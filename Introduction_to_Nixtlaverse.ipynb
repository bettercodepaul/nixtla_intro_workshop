{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/bettercodepaul/nixtla_intro_workshop/blob/main/Introduction_to_Nixtlaverse.ipynb\">\n",
        "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLXb0BBRFy7C"
      },
      "source": [
        "# Introduction to Forecasting with Nixtla's Nixtlaverse\n",
        "\n",
        "This notebook walks you through the very basics of forecasting time series with Nixtla's Nixtlaverse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ7KgpyEGTs5"
      },
      "source": [
        "## Install and import necessary libraries\n",
        "\n",
        "We use [Polars](https://docs.pola.rs/) for data wrangling, [Plotly](https://plotly.com/python/plotly-express/) for visualizations and Nixtla's [StatsForecast](https://nixtlaverse.nixtla.io/statsforecast/index.html) for basic time series forecasting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK4r_pvhQDOi"
      },
      "outputs": [],
      "source": [
        "pip -q install statsforecast polars plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWDpn06iP2VY"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import plotly.express as px\n",
        "from statsforecast import StatsForecast\n",
        "from datetime import date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us-tgF0XGoy7"
      },
      "source": [
        "## Initial Exploration of the data\n",
        "\n",
        "The data for this walk through is simple monthly sales data from various countries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "-qgnbWMtP7w3",
        "outputId": "ad500f9b-7988-45c9-93b1-42b4c50e96eb"
      },
      "outputs": [],
      "source": [
        "# load the dataset\n",
        "df = pl.read_parquet(\"https://github.com/bettercodepaul/nixtla_intro_workshop/raw/refs/heads/main/retail_sales.parquet\")\n",
        "# show a sample of 5 rows\n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL0YKBwvIDAk"
      },
      "source": [
        "We can visualize the time series with Plotly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "QFpv7_4Z_Uhl",
        "outputId": "af7998cb-23b1-4b9f-aeef-5525070d58e6"
      },
      "outputs": [],
      "source": [
        "# This shows a line plot with the sales data for each country\n",
        "# Plotly comes with useful interactive features: zoom, hover and trace isolation in the legend via click/double click\n",
        "px.line(df, x=\"date\", y=\"sales\", color=\"country\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "zZC_aFdMFTP-",
        "outputId": "b703cbaf-f1f8-4b86-dbe1-486420127d85"
      },
      "outputs": [],
      "source": [
        "# Too many overlapping lines?\n",
        "# We can use a facet plot that creates a separate plot for each country\n",
        "fig = px.line(df, x=\"date\", y=\"sales\", facet_col=\"country\", facet_col_wrap=2)\n",
        "fig.update_yaxes(matches=None) # This ensures that each subplot has its own y-axis scale\n",
        "fig.update_layout(height=800) # Adjust the height to fit all subplots nicely\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QKZDZv7H5Es"
      },
      "source": [
        "# Hands-on: Exploratory Data Dibbling\n",
        "\n",
        "Explore the time series! What do you find interesting? Are there any obvious patterns? Are there any outliers? What could be the reasons?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI_G2Q2EIi8V"
      },
      "outputs": [],
      "source": [
        "# you can either code here your own explorations or just use the interactive diagrams above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparing the data for Nixtla\n",
        "\n",
        "Nixtla follows a specific naming convention for the time series data.\n",
        "\n",
        "- `unique_id`: an identifier to distinguish different time series in the same data set\n",
        "- `ds`: the date or time column\n",
        "- `y`: the actual value of the time series at that time\n",
        "\n",
        "We rename the columns accordingly so that we don't have to specify the column names later on every method call.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRZYKrzV_z2t"
      },
      "outputs": [],
      "source": [
        "Y_df = df.rename(\n",
        "    {\n",
        "        \"date\": \"ds\",\n",
        "        \"sales\": \"y\",\n",
        "        \"country\": \"unique_id\",\n",
        "    }\n",
        ")\n",
        "Y_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875
        },
        "id": "CyHn0Jkc_3LE",
        "outputId": "01494f19-811b-47d4-fd39-204abb9613d7"
      },
      "outputs": [],
      "source": [
        "# Nixtla supports plotting time series using matplotlib, but we normally prefer Plotly for its interactive plots.\n",
        "StatsForecast.plot(Y_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psTTwljLIqAL"
      },
      "source": [
        "## Forecasting using Nixtla's StatsForecast\n",
        "\n",
        "Nixtla's StatsForecast package comes with a lot of classic forecasting algorithms. We won't go into the details of the different algorithms in this workshop. If you would like to know more details about them we highly recommend the freely available book [\"Forecasting: Principles and Practice, the Pythonic Way\"](https://otexts.com/fpppy/) by Rob Hyndman.\n",
        "\n",
        "As you might have noticed, the data contains a strong seasonal component in each year.\n",
        "This is caused by different cultural habits, business practices and laws in each country.\n",
        "\n",
        "Most algorithms that support to model this seasonal component have to be given the seasonal length. As we have a yearly seasonality and monthly data the seasonal length will be 12, which means that every 12 time steps the same period is repeated.\n",
        "\n",
        "We will use 4 models in this example:\n",
        "\n",
        "- [`HistoricAverage`](https://nixtlaverse.nixtla.io/statsforecast/src/core/models.html#historicaverage): forecast the mean of all past observations\n",
        "- [`SeasonalNaive`](https://nixtlaverse.nixtla.io/statsforecast/src/core/models.html#seasonalnaive): forecast the last value of the same period (e.g. the same month of the previous year)\n",
        "- [`HoltWinters`](https://nixtlaverse.nixtla.io/statsforecast/src/core/models.html#holtwinters): an exponential smoothing model, that models trend and seasonality\n",
        "- [`AutoARIMA`](https://nixtlaverse.nixtla.io/statsforecast/src/core/models.html#autoarima): THE classic time series model, that models trend and seasonality. The parameters for the underlying SARIMA model are automatically selected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-hPzz4B_7yG"
      },
      "outputs": [],
      "source": [
        "from statsforecast.models import (\n",
        "    HistoricAverage,\n",
        "    SeasonalNaive,\n",
        "    HoltWinters,\n",
        "    AutoARIMA,\n",
        ")\n",
        "models = [\n",
        "    HistoricAverage(),\n",
        "    SeasonalNaive(season_length=12),\n",
        "    HoltWinters(season_length=12),\n",
        "    AutoARIMA(season_length=12),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJoeUuS4BvwW"
      },
      "outputs": [],
      "source": [
        "# initialize the StatsForecast object with the models and frequency\n",
        "sf = StatsForecast(\n",
        "    models=models,\n",
        "    freq=\"1mo\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "zGJhT038Ao1S",
        "outputId": "ddc76913-848e-4e33-e476-7e8f543ffbe3"
      },
      "outputs": [],
      "source": [
        "# create a forecast for the next 48 months (4 years) using all available data and all models\n",
        "forecasts_df = sf.forecast(df=Y_df, h=48)\n",
        "forecasts_df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use Plotly to visualize the forecast."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "pk7JgBzVKF6L",
        "outputId": "d4616900-f86d-4fda-cc89-452968623527"
      },
      "outputs": [],
      "source": [
        "# append the forecasts to the original data\n",
        "plot_df = pl.concat([Y_df, forecasts_df], how=\"diagonal\")\n",
        "\n",
        "# you could filter the data to only show a subset of countries\n",
        "# plot_df = plot_df.filter(pl.col(\"unique_id\").is_in([\"Italien\", \"Japan\"]))\n",
        "\n",
        "# or you could select only a subset of the models\n",
        "# plot_df = plot_df.select(\"unique_id\", \"ds\", \"y\", \"SeasonalNaive\", \"AutoARIMA\")\n",
        "\n",
        "y_columns = [c for c in plot_df.columns if c not in [\"unique_id\", \"ds\"]]\n",
        "fig = px.line(plot_df, x=\"ds\", y=y_columns, facet_col=\"unique_id\", facet_col_wrap=2)\n",
        "fig.update_yaxes(matches=None)\n",
        "fig.update_layout(height=800)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# the Nixtla equivalent to the code above is more concise, but less interactive\n",
        "# sf.plot(Y_df, forecasts_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZowsR1HL_3B"
      },
      "source": [
        "## Hands-on: Eyeballed Forecast Analysis\n",
        "\n",
        "Explore the forecasts! What do you find interesting? Are the models capable of reproducing the seasonal patterns? Is there a model you would prefer over the others?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t45rltZtLo_d"
      },
      "outputs": [],
      "source": [
        "# you can either code here your own explorations or just use the interactive diagrams above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make another forecast, but now start at January 2018"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y_df_before_2018 = Y_df.filter(pl.col(\"ds\").dt.year().lt(2018))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# use the code from above to create the forecast using Y_df_before_2018\n",
        "# visualize the forecast using the code from above, but still us Y_df, so that you can compare the forecast with the actual values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i25DgdnXNvlS"
      },
      "source": [
        "## Forecast Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q12zphWeXa8L"
      },
      "source": [
        "As demonstrated in the hands-on example, we can evaluate the accuracy of our model by comparing its forecasts for past periods (derived from \"old data\") to the actual values we already know today.\n",
        "\n",
        "However, one of the most significant challenges in validating forecasts with this method is future leakage. It is crucial to ensure that the forecasts are not influenced by future data, as doing so would compromise the integrity of the evaluation. Unfortunately, in practice, completely avoiding future leakage is almost impossible. During the creation of the final forecasting system, many decisions must be made, and these decisions are often (unconsciously) influenced by information from the entire dataset.\n",
        "\n",
        "Using a naive, random cross-validation scheme would definitely introduce future leakage. In such a scenario, the model would have access to data from the entire time period, allowing it to \"learn\" about future trends or events. This would lead to an overly optimistic cross-validation score that does not reflect the model's true performance on unseen data.\n",
        "\n",
        "To mitigate this risk, we employ a specialized cross-validation scheme designed for time series data. This approach is often referred to as sliding window or expanding window validation. These techniques ensure a more robust evaluation of the model's predictive abilities across a wider range of temporal instances while maintaining critical properties:\n",
        "\n",
        "1. the training data remains contiguous, adhering to the requirements of time series models, and\n",
        "2. future data is systematically excluded from influencing the model during training.\n",
        "\n",
        "By adhering to this method, we can arrive at a more realistic estimate of how well our model is likely to perform in practice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "uEZM7PQgNyeH",
        "outputId": "4532623a-802f-42ff-ee5a-72a34e00f2c3"
      },
      "outputs": [],
      "source": [
        "# visualization of an expanding window validation\n",
        "from IPython.display import Image\n",
        "Image(url=\"https://raw.githubusercontent.com/Nixtla/statsforecast/main/nbs/imgs/ChainedWindows.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtXkVBcGOmZ1"
      },
      "source": [
        "The `cross_validation` method from the `StatsForecast` class performs expanding window validation by default and accepts the following arguments:\n",
        "\n",
        "- `df`: The training data frame containing the historical data.\n",
        "- `h (int)`: The forecast horizon, representing the number of steps into the future to be forecasted. For example, in our case, this is set to 24 months.\n",
        "- `step_size (int)`: The number of time steps by which the window is shifted for each validation iteration. In other words, this controls how far the window moves forward during the cross-validation process.\n",
        "- `n_windows(int)`: The number of validation windows used for cross-validation. In other words, this determines how many historical forecasting processes you want to evaluate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73IslhIIOaOM"
      },
      "outputs": [],
      "source": [
        "# this takes some time...\n",
        "cv_df = sf.cross_validation(\n",
        "    df=Y_df,\n",
        "    h=24,\n",
        "    step_size=24, # try step_size 12 as well -> overlapping windows\n",
        "    n_windows=4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "kiM7O9_gO6PC",
        "outputId": "f40fa5b0-163d-4c07-dd5e-60559cb8e23d"
      },
      "outputs": [],
      "source": [
        "# you can check the resulting windows of the expanding window validation\n",
        "windows = cv_df.group_by(\"cutoff\").agg(pl.col(\"ds\").max()).sort(\"cutoff\")\n",
        "windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "qxkweoZcPrby",
        "outputId": "6267fe2d-1fb4-4bb2-fe0a-e0ee5cf9097f"
      },
      "outputs": [],
      "source": [
        "colors = px.colors.qualitative.Plotly # used to color the windows\n",
        "\n",
        "# create a line plot of the world wide monthly sales\n",
        "fig = px.line(Y_df.group_by(\"ds\").agg(pl.col(\"y\").sum()).sort(\"ds\"), x=\"ds\", y=\"y\")\n",
        "\n",
        "# add the windows as vertical rectangles to the plot\n",
        "for idx, window in enumerate(windows.rows()):\n",
        "    start = window[0]\n",
        "    end = window[1]\n",
        "    fig.add_vrect(x0=start, x1=end, fillcolor=colors[idx%len(colors)], opacity=0.2)\n",
        "    fig.add_annotation(x=window[0], xshift=5, xanchor=\"left\", text=f\"Window {idx+1}<BR>{start:%m/%y} - {end:%m/%y}\", align=\"left\", font=dict(color=\"grey\"), showarrow=False)\n",
        "\n",
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hands-on: Validation Judgement\n",
        "\n",
        "Time series validation presents unique challenges because you often don’t have enough data to capture all relevant patterns.\n",
        "\n",
        "- Seasonal models, for instance, require at least two periods of data (and almost all our data generating processes have a yearly seasonality!)\n",
        "- Long-term trends evolve slowly, and in a start-up, the data may only reflect steady growth, making it nearly impossible for the model to predict a decline if it has never encountered one.\n",
        "- Furthermore, rare events like pandemics or financial crises occur infrequently, perhaps once a decade, leaving little precedent to learn from.\n",
        "\n",
        "Look at the data and the windows. Will this validation scheme be representative? Can we improve? What are the trade-offs?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Room for your thoughts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhpqnktcYJpO"
      },
      "source": [
        "## Forecast Evaluation\n",
        "\n",
        "There are several error metrics we can use to evaluate the models based on the forecast from the expanding window validation.\n",
        "\n",
        "- **Mean Absolute Error**: [`mae`](https://nixtlaverse.nixtla.io/utilsforecast/losses.html#mean-absolute-error-mae)\n",
        "    - measures the average forecasting accuracy using the absolute deviation\n",
        "- **Root Mean Squared Error**: [`rmse`](https://nixtlaverse.nixtla.io/utilsforecast/losses.html#root-mean-squared-error)\n",
        "    - measures the average forecasting accuracy using the squared deviation\n",
        "- **Bias**: [`bias`](https://nixtlaverse.nixtla.io/utilsforecast/losses.html#bias)\n",
        "    - measures the average forecasting bias using the deviation\n",
        "- **Mean Absolute Percentage Error**: [`mape`](https://nixtlaverse.nixtla.io/utilsforecast/losses.html#mean-absolute-percentage-error)\n",
        "    - measures the average forecasting accuracy using the absolute relative deviation\n",
        "    - use this only for communication with stakeholders, not for choosing or comparing models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvJE4np3QgDK"
      },
      "outputs": [],
      "source": [
        "from utilsforecast.losses import mae, rmse, bias, mape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vDEgywyVrry"
      },
      "outputs": [],
      "source": [
        "def evaluate_cv(df, metric):\n",
        "    models = [c for c in df.columns if c not in ('unique_id', 'ds', 'cutoff', 'y')]\n",
        "    evals = metric(cv_df, models=models)\n",
        "    pos2model = dict(enumerate(models))\n",
        "    return evals.with_columns(\n",
        "        best_model=pl.concat_list(models).list.arg_min().replace_strict(pos2model)\n",
        "    ).with_columns(pl.selectors.float().round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "bvg8ng8vVx9A",
        "outputId": "5e3c471e-d59a-481f-ccdb-cf2ab2359f3f"
      },
      "outputs": [],
      "source": [
        "evaluation_df = evaluate_cv(cv_df, rmse)\n",
        "evaluation_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hands-on: Forecast Evaluation\n",
        "\n",
        "Try the different error metrics. Is it always the same model that \"wins\"?\n",
        "\n",
        "Compare with a different validation scheme (different `n_windows` or `step_size`) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Room for your analysis"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
