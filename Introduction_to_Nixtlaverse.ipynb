{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/bettercodepaul/nixtla_intro_workshop/blob/main/Introduction_to_Nixtlaverse.ipynb\">\n",
        "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLXb0BBRFy7C"
      },
      "source": [
        "# Introduction to Forecasting with Nixtla's Nixtlaverse\n",
        "\n",
        "This notebook walks you through the very basics of forecasting time series with Nixtla's Nixtlaverse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ7KgpyEGTs5"
      },
      "source": [
        "## Install and import necessary libraries\n",
        "\n",
        "We use [Polars](https://docs.pola.rs/) for data wrangling, [Plotly](https://plotly.com/python/plotly-express/) for visualizations and Nixtla's [StatsForecast](https://nixtlaverse.nixtla.io/statsforecast/index.html) for basic time series forecasting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK4r_pvhQDOi"
      },
      "outputs": [],
      "source": [
        "pip -q install statsforecast polars plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download utility module\n",
        "import urllib.request\n",
        "import os.path\n",
        "UTILS_URL = \"https://github.com/bettercodepaul/nixtla_intro_workshop/raw/main/utilities.py\"\n",
        "urllib.request.urlretrieve(UTILS_URL, os.path.basename(UTILS_URL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWDpn06iP2VY"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import plotly.express as px\n",
        "from statsforecast import StatsForecast\n",
        "from datetime import date\n",
        "import utilities as bcxp_ts_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Time Series\n",
        "\n",
        "A time series is a collection of data points recorded or observed at consistent, regular intervals over time, such as hourly, daily, monthly, or yearly. This type of data captures how certain metrics or phenomena evolve over time, making it an essential tool for analyzing trends, forecasting future values, and understanding temporal patterns.\n",
        "\n",
        "- **Population trends**\n",
        "    - Example: The population of a city measured at the start of each year from 2000 to 2020.\n",
        "- **Economic indicators**\n",
        "    - Example: The national unemployment rate recorded monthly by a government agency.\n",
        "- **Stock market data**\n",
        "    - Example: The daily closing price of a company's stock for the past six months.\n",
        "- **Production data**\n",
        "    - Example: The number of cars produced in a factory each month over the last three years.\n",
        "- **Sales performance**\n",
        "    - Example: The weekly sales revenue of an online store during a calendar year.\n",
        "- **Resource utilization**\n",
        "    - Example: The hourly CPU usage of a server over 24 hours.\n",
        "- **Energy consumption**\n",
        "    - Example: The daily electricity consumption of a household over a year.\n",
        "- **Sensor data**\n",
        "    - Example: Hourly temperature readings from a weather station for one month."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us-tgF0XGoy7"
      },
      "source": [
        "## Initial Exploration of the data\n",
        "\n",
        "The data for this walk through is simple monthly sales data from various countries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "-qgnbWMtP7w3",
        "outputId": "ad500f9b-7988-45c9-93b1-42b4c50e96eb"
      },
      "outputs": [],
      "source": [
        "# load the dataset\n",
        "Y_df = pl.read_parquet(\"https://github.com/bettercodepaul/nixtla_intro_workshop/raw/refs/heads/main/retail_sales.parquet\")\n",
        "# show a sample of 5 rows\n",
        "Y_df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nixtla follows a specific naming convention for the time series data.\n",
        "\n",
        "- `unique_id`: an identifier to distinguish different time series in the same data set\n",
        "- `ds`: the date or time column\n",
        "- `y`: the actual value of the time series at that time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL0YKBwvIDAk"
      },
      "source": [
        "We can visualize the time series with Plotly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "QFpv7_4Z_Uhl",
        "outputId": "af7998cb-23b1-4b9f-aeef-5525070d58e6"
      },
      "outputs": [],
      "source": [
        "# This shows a line plot with the sales data for each country\n",
        "# Plotly comes with useful interactive features: zoom, hover and trace isolation in the legend via click/double click\n",
        "px.line(Y_df, x=\"ds\", y=\"y\", color=\"unique_id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "zZC_aFdMFTP-",
        "outputId": "b703cbaf-f1f8-4b86-dbe1-486420127d85"
      },
      "outputs": [],
      "source": [
        "# StatsForecast comes with a utility that can create a faceted plot for each time series in the dataset\n",
        "StatsForecast.plot(Y_df, unique_ids=[\"Deutschland\", \"Frankreich\", \"Italien\", \"Grossbritannien\", \"Japan\", \"USA\"], engine=\"plotly\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QKZDZv7H5Es"
      },
      "source": [
        "# Hands-on: Exploratory Data Dibbling\n",
        "\n",
        "Explore the time series! What do you find interesting? Are there any obvious patterns? Are there any outliers? What could be the reasons?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI_G2Q2EIi8V"
      },
      "outputs": [],
      "source": [
        "# you can either code here your own explorations or just use the interactive diagrams above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the Structure and Influences of Time Series Data\n",
        "\n",
        "There are fundamental truths that remain constant over time. For instance, physical laws govern natural processes, and basic economic principles, like the relationship between supply and demand, operate consistently. Additionally, controlled lab experiments, when repeated, yield the same results regardless of timing.\n",
        "\n",
        "However, much of the data we analyze in reality is time-dependent. Long-term trends, such as the emergence of new technologies or the implementation of new regulations, evolve over broader periods. Meanwhile, short-term events like a strike or a marketing campaign can significantly impact data. Seasonal patterns, like spikes in retail sales during holidays, also create recurring fluctuations.\n",
        "\n",
        "Human behavior often adds another layer of influence. For example, companies might increase sales figures at year-end using creative methods just to meet annual targets.\n",
        "\n",
        "To understand time series data, we typically break it down into three components:\n",
        "\n",
        "- **Trend**: The overall direction of the data over time (e.g., population growth or declining energy usage).\n",
        "- **Seasonality**: Regular patterns that repeat within fixed intervals, like weekly sales cycles or holiday shopping spikes.\n",
        "- **Residual**: Unpredictable variations or noise, caused by random events or minor anomalies.\n",
        "\n",
        "The environment, including the day-night cycle or seasonal shifts, plays a significant role in shaping time series across all domains, as illustrated in the graphic below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Decompose the time series data using a multiplicative model and monthly seasonality (this uses StatsModels seasonal_decompose under the hood)\n",
        "df_decomposed = bcxp_ts_utils.decompose(Y_df, model=\"multiplicative\", period=12)\n",
        "df_decomposed.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot the components for a single time series\n",
        "bcxp_ts_utils.plot_components(df_decomposed, unique_id=\"Japan\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot the trend component for all time series in the dataset\n",
        "px.line(df_decomposed, x=\"ds\", y=\"trend\", color=\"unique_id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot the seasonal component for a single time series in a bar polar plot\n",
        "bcxp_ts_utils.plot_seasonality(df_decomposed, unique_id=\"Japan\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot the seasonal components for all time series in the dataset\n",
        "bcxp_ts_utils.plot_seasonalities(df_decomposed, facet_col_wrap=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psTTwljLIqAL"
      },
      "source": [
        "## Forecasting using Nixtla's StatsForecast\n",
        "\n",
        "Nixtla's StatsForecast package comes with a lot of classic forecasting algorithms. We won't go into the details of the different algorithms in this workshop. If you would like to know more details about them we highly recommend the freely available book [\"Forecasting: Principles and Practice, the Pythonic Way\"](https://otexts.com/fpppy/) by Rob Hyndman.\n",
        "\n",
        "As you might have noticed, the data contains a strong seasonal component in each year.\n",
        "This is caused by different cultural habits, business practices and laws in each country.\n",
        "\n",
        "Most algorithms that support to model this seasonal component have to be given the seasonal length. As we have a yearly seasonality and monthly data the seasonal length will be 12, which means that every 12 time steps the same period is repeated.\n",
        "\n",
        "We will use 4 models in this example:\n",
        "\n",
        "- [`HistoricAverage`](https://nixtlaverse.nixtla.io/statsforecast/src/core/models.html#historicaverage): forecast the mean of all past observations\n",
        "- [`SeasonalNaive`](https://nixtlaverse.nixtla.io/statsforecast/src/core/models.html#seasonalnaive): forecast the last value of the same period (e.g. the same month of the previous year)\n",
        "- [`HoltWinters`](https://nixtlaverse.nixtla.io/statsforecast/src/core/models.html#holtwinters): an exponential smoothing model, that models trend and seasonality\n",
        "- [`AutoARIMA`](https://nixtlaverse.nixtla.io/statsforecast/src/core/models.html#autoarima): THE classic time series model, that models trend and seasonality. The parameters for the underlying SARIMA model are automatically selected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-hPzz4B_7yG"
      },
      "outputs": [],
      "source": [
        "from statsforecast.models import (\n",
        "    HistoricAverage,\n",
        "    SeasonalNaive,\n",
        "    HoltWinters,\n",
        "    AutoARIMA,\n",
        ")\n",
        "models = [\n",
        "    HistoricAverage(),\n",
        "    SeasonalNaive(season_length=12),\n",
        "    HoltWinters(season_length=12),\n",
        "    AutoARIMA(season_length=12),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJoeUuS4BvwW"
      },
      "outputs": [],
      "source": [
        "# initialize the StatsForecast object with the models and frequency\n",
        "sf = StatsForecast(\n",
        "    models=models,\n",
        "    freq=\"1mo\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "zGJhT038Ao1S",
        "outputId": "ddc76913-848e-4e33-e476-7e8f543ffbe3"
      },
      "outputs": [],
      "source": [
        "# create a forecast for the next 48 months (4 years) using all available data and all models\n",
        "forecasts_df = sf.forecast(df=Y_df, h=48)\n",
        "forecasts_df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We visualize the forecasts of the different models for the different countries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sf.plot(Y_df, forecasts_df, engine=\"plotly\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZowsR1HL_3B"
      },
      "source": [
        "## Hands-on: Eyeballed Forecast Analysis\n",
        "\n",
        "Explore the forecasts! What do you find interesting? Are the models capable of reproducing the seasonal patterns? Does the model forecast a certain trend? Is there a model you would prefer over the others? Does the forecasted minimum value make sense for all models?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t45rltZtLo_d"
      },
      "outputs": [],
      "source": [
        "# you can either code here your own explorations or just use the interactive diagrams above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Make another forecast, but now start at January 2018"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Y_df_before_2018 = Y_df.filter(pl.col(\"ds\").dt.year().lt(2018))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# use the code from above to create the forecast using Y_df_before_2018\n",
        "# visualize the forecast using the code from above, but still us Y_df, so that you can compare the forecast with the actual values\n",
        "# what do you observe? Does the forecast interpolation of the past trend look right? How did the trend actually develop?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i25DgdnXNvlS"
      },
      "source": [
        "## Forecast Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q12zphWeXa8L"
      },
      "source": [
        "As demonstrated in the hands-on example, we can evaluate the accuracy of our model by comparing its forecasts for past periods (derived from \"old data\") to the actual values we already know today.\n",
        "\n",
        "However, one of the most significant challenges in validating forecasts with this method is future leakage. It is crucial to ensure that the forecasts are not influenced by future data, as doing so would compromise the integrity of the evaluation. Unfortunately, in practice, completely avoiding future leakage is almost impossible. During the creation of the final forecasting system, many decisions must be made, and these decisions are often (unconsciously) influenced by information from the entire dataset.\n",
        "\n",
        "Using a naive, random cross-validation scheme would definitely introduce future leakage. In such a scenario, the model would have access to data from the entire time period, allowing it to \"learn\" about future trends or events. This would lead to an overly optimistic cross-validation score that does not reflect the model's true performance on unseen data.\n",
        "\n",
        "To mitigate this risk, we employ a specialized cross-validation scheme designed for time series data. This approach is often referred to as rolling cross-validation with a sliding window or expanding window. These techniques ensure a more robust evaluation of the model's predictive abilities across a wider range of temporal instances while maintaining critical properties:\n",
        "\n",
        "1. the training data remains contiguous, adhering to the requirements of time series models, and\n",
        "2. future data is systematically excluded from influencing the model during training.\n",
        "\n",
        "By adhering to this method, we can arrive at a more realistic estimate of how well our model is likely to perform in practice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "uEZM7PQgNyeH",
        "outputId": "4532623a-802f-42ff-ee5a-72a34e00f2c3"
      },
      "outputs": [],
      "source": [
        "# visualization of a rolling cross-validation with an expanding window\n",
        "from IPython.display import Image\n",
        "Image(url=\"https://raw.githubusercontent.com/Nixtla/statsforecast/main/nbs/imgs/ChainedWindows.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtXkVBcGOmZ1"
      },
      "source": [
        "The `cross_validation` method from the `StatsForecast` class performs a rolling cross-validation with an expanding window by default and accepts the following arguments:\n",
        "\n",
        "- `df`: The training data frame containing the historical data.\n",
        "- `h (int)`: The forecast horizon, representing the number of steps into the future to be forecasted. For example, in our case, this is set to 24 months.\n",
        "- `step_size (int)`: The number of time steps by which the window is shifted for each validation iteration. In other words, this controls how far the window moves forward during the cross-validation process.\n",
        "- `n_windows(int)`: The number of validation windows used for cross-validation. In other words, this determines how many historical forecasting processes you want to evaluate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73IslhIIOaOM"
      },
      "outputs": [],
      "source": [
        "# this takes some time...\n",
        "cv_df = sf.cross_validation(\n",
        "    df=Y_df,\n",
        "    h=24,\n",
        "    step_size=24, # try step_size 12 as well -> overlapping windows\n",
        "    n_windows=4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "kiM7O9_gO6PC",
        "outputId": "f40fa5b0-163d-4c07-dd5e-60559cb8e23d"
      },
      "outputs": [],
      "source": [
        "# you can check the resulting windows of the expanding window validation\n",
        "windows = cv_df.group_by(\"cutoff\").agg(pl.col(\"ds\").max()).sort(\"cutoff\")\n",
        "windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "qxkweoZcPrby",
        "outputId": "6267fe2d-1fb4-4bb2-fe0a-e0ee5cf9097f"
      },
      "outputs": [],
      "source": [
        "colors = px.colors.qualitative.Plotly # used to color the windows\n",
        "\n",
        "# create a line plot of the world wide monthly sales\n",
        "fig = px.line(Y_df.group_by(\"ds\").agg(pl.col(\"y\").sum()).sort(\"ds\"), x=\"ds\", y=\"y\")\n",
        "\n",
        "# add the windows as vertical rectangles to the plot\n",
        "for idx, window in enumerate(windows.rows()):\n",
        "    start = window[0]\n",
        "    end = window[1]\n",
        "    fig.add_vrect(x0=start, x1=end, fillcolor=colors[idx%len(colors)], opacity=0.2)\n",
        "    fig.add_annotation(x=window[0], xshift=5, xanchor=\"left\", text=f\"Window {idx+1}<BR>{start:%m/%y} - {end:%m/%y}\", align=\"left\", font=dict(color=\"grey\"), showarrow=False)\n",
        "\n",
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hands-on: Validation Judgement\n",
        "\n",
        "Time series validation presents unique challenges because you often don’t have enough data to capture all relevant patterns.\n",
        "\n",
        "- Seasonal models, for instance, require at least two periods of data (and almost all our data generating processes have a yearly seasonality!)\n",
        "- Long-term trends evolve slowly, and in a start-up, the data may only reflect steady growth, making it nearly impossible for the model to predict a decline if it has never encountered one.\n",
        "- Furthermore, rare events like pandemics or financial crises occur infrequently, perhaps once a decade, leaving little precedent to learn from.\n",
        "\n",
        "Look at the data and the windows. Will this validation scheme be representative? Can we improve? What are the trade-offs?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Room for your thoughts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhpqnktcYJpO"
      },
      "source": [
        "## Forecast Evaluation\n",
        "\n",
        "There are several error metrics we can use to evaluate the models based on the forecast from the rolling cross-validation.\n",
        "\n",
        "- **Mean Absolute Error**: [`mae`](https://nixtlaverse.nixtla.io/utilsforecast/losses.html#mean-absolute-error-mae)\n",
        "    - measures the forecasting accuracy using the absolute deviation $\\left|\\hat{y}_t - y_t\\right|$\n",
        "- **Root Mean Squared Error**: [`rmse`](https://nixtlaverse.nixtla.io/utilsforecast/losses.html#root-mean-squared-error)\n",
        "    - measures the forecasting accuracy using the squared deviation $\\left(\\hat{y}_t - y_t\\right)^2$\n",
        "- **Bias**: [`bias`](https://nixtlaverse.nixtla.io/utilsforecast/losses.html#bias)\n",
        "    - measures the forecasting bias using the deviation $\\hat{y}_t - y_t$\n",
        "- **Mean Absolute Percentage Error**: [`mape`](https://nixtlaverse.nixtla.io/utilsforecast/losses.html#mean-absolute-percentage-error)\n",
        "    - measures the forecasting accuracy using the absolute *relative* deviation $\\left|\\frac{\\hat{y}_t - y_t}{y_t}\\right|$\n",
        "    - you can use this for communication with stakeholders, but beware when comparing or choosing models\n",
        "    - it is problematic when $y_t \\approx 0$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvJE4np3QgDK"
      },
      "outputs": [],
      "source": [
        "from utilsforecast.losses import mae, rmse, bias, mape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vDEgywyVrry"
      },
      "outputs": [],
      "source": [
        "def evaluate_cv(df, metric):\n",
        "    models = [c for c in df.columns if c not in ('unique_id', 'ds', 'cutoff', 'y')]\n",
        "    evals = metric(cv_df, models=models)\n",
        "    pos2model = dict(enumerate(models))\n",
        "    return evals.with_columns(\n",
        "        best_model=pl.concat_list(models).list.arg_min().replace_strict(pos2model)\n",
        "    ).with_columns(pl.selectors.float().round(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "bvg8ng8vVx9A",
        "outputId": "5e3c471e-d59a-481f-ccdb-cf2ab2359f3f"
      },
      "outputs": [],
      "source": [
        "evaluation_df = evaluate_cv(cv_df, rmse)\n",
        "evaluation_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hands-on: Forecast Evaluation\n",
        "\n",
        "Try the different error metrics. Is it always the same model that \"wins\"?\n",
        "\n",
        "Compare with a different validation scheme (different `n_windows` or `step_size`) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Room for your analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Additional topics and Take home assignments\n",
        "\n",
        "\n",
        "You can explore various topics we could not cover today!\n",
        "\n",
        "- Try different transformations of the target value, e.g. using the Box-Cox-Transformation. See https://otexts.com/fpppy/nbs/05-toolbox.html#sec-ftransformations\n",
        "- Try a fixed size for the training window in the cross-validation (e.g. `input_size=4` years) to get a sliding window.\n",
        "- Explore all available models. See https://nixtlaverse.nixtla.io/statsforecast/index.html#models\n",
        "- Explore all available metrics. See https://nixtlaverse.nixtla.io/utilsforecast/losses.html\n",
        "- Check out how to include exogenuous regressors. See https://nixtlaverse.nixtla.io/statsforecast/docs/how-to-guides/exogenous.html\n",
        "- Check out how to include multiple seasonalities. See https://nixtlaverse.nixtla.io/statsforecast/docs/tutorials/multipleseasonalities.html"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
