{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/bettercodepaul/nixtla_intro_workshop/blob/main/Introduction_to_MLForecast.ipynb\">\n",
        "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLXb0BBRFy7C"
      },
      "source": [
        "# Introduction to Forecasting with Nixtla's mlforecast\n",
        "\n",
        "This notebook walks you through the very basics of forecasting time series with Nixtla's mlforecast."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ7KgpyEGTs5"
      },
      "source": [
        "## Install and import necessary libraries\n",
        "\n",
        "We use [Polars](https://docs.pola.rs/) for data wrangling, [Plotly](https://plotly.com/python/plotly-express/) for visualizations and Nixtla's [mlforecast](https://nixtlaverse.nixtla.io/mlforecast/index.html) for time series forecasting with machine learning algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK4r_pvhQDOi"
      },
      "outputs": [],
      "source": [
        "pip -q install mlforecast polars plotly scikit-learn==1.5.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWDpn06iP2VY",
        "outputId": "91cae4c7-430c-4908-8b85-10a4d0c8e5c3"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "import polars as pl\n",
        "import plotly.express as px\n",
        "from datetime import date\n",
        "from mlforecast import MLForecast\n",
        "from mlforecast.lag_transforms import ExpandingMean, RollingMean\n",
        "from mlforecast.target_transforms import Differences\n",
        "from utilsforecast.plotting import plot_series\n",
        "\n",
        "pl.Config(tbl_rows=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-iCk7RP3nJ7"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us-tgF0XGoy7"
      },
      "source": [
        "## Initial Exploration of the data\n",
        "\n",
        "The data for this walk through is monthly sales data for various countries and products."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "-qgnbWMtP7w3",
        "outputId": "ca4fb686-160a-47be-9d45-87a2d464bc62"
      },
      "outputs": [],
      "source": [
        "Y_df = pl.read_parquet(\"https://github.com/bettercodepaul/nixtla_intro_workshop/raw/refs/heads/main/retail_sales_product_level.parquet\")\n",
        "Y_df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL0YKBwvIDAk"
      },
      "source": [
        "We can visualize the time series with Plotly. The sales volume on the country level is the same as in the introducing notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_series(Y_df.group_by(pl.col(\"country\").alias(\"unique_id\"), \"ds\").agg(pl.col(\"y\").sum()).sort(\"ds\"), ids=[\"Deutschland\", \"Frankreich\", \"Italien\", \"Grossbritannien\", \"Japan\", \"USA\"], engine=\"plotly\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2hvXWOzrtNL"
      },
      "source": [
        "However, in this data we also have sales on the product level. For example we can visualize the sales for all products of type *elegant* and segment *medium*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "zZC_aFdMFTP-",
        "outputId": "0c646784-53c4-4cd7-d91f-89d2e091913b"
      },
      "outputs": [],
      "source": [
        "product_type = \"elegant\" # elegant or comfortable\n",
        "product_segment = \"big\" # small, medium or big\n",
        "df_plot = (\n",
        "    Y_df\n",
        "    .filter(pl.col(\"type\").eq(product_type) & pl.col(\"segment\").eq(product_segment))\n",
        "    .group_by(\"ds\", \"version\")\n",
        "    .agg(pl.col(\"y\").sum())\n",
        "    .sort(\"ds\")\n",
        ")\n",
        "px.line(df_plot, x=\"ds\", y=\"y\", color=\"version\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Local Models vs Global Models\n",
        "\n",
        "Classic time series model like ARIMA, Exponential Smoothing and GARCH always operate on single time series. They learn from the past of this single time series to forecast the future.\n",
        "\n",
        "![Local Models](https://github.com/bettercodepaul/nixtla_intro_workshop/blob/main/images/Local%20Models.png?raw=true)\n",
        "\n",
        "Global models on the other hand learn from various time series at once. Relationships and patterns learned from one time series can be transferred to other time series in a global model.\n",
        "\n",
        "Caution: Just because a model is global doesn't mean that the model treats all time series uniformly. It is therefore possible that the global model in our example handles Spain differently than Italy.\n",
        "\n",
        "Global models often also have an advantage in addressing the so-called cold start problem. This is when a new time series needs to be predicted, but no prior data is available for it.\n",
        "\n",
        "![Global Models](https://github.com/bettercodepaul/nixtla_intro_workshop/blob/main/images/Global%20Models.png?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psTTwljLIqAL"
      },
      "source": [
        "## Transforming the data to be suitable for Machine Learning\n",
        "\n",
        "We need to transform the data to be able to feed it into a Machine Learning algorithm, because these algorithms are built to look at a row with different features and a target value.\n",
        "\n",
        "![Machine Learning Models](https://github.com/bettercodepaul/nixtla_intro_workshop/blob/main/images/Machine%20Learning%20Models.png?raw=true)\n",
        "\n",
        "For time series a classic feature is the lag of the time series. That is the value the time series had in the past. E.g. a lag 1 feature would be the value of the target one time step before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3pX0ysatQbv"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "    lgb.LGBMRegressor(random_state=0, verbosity=-1),\n",
        "]\n",
        "fcst = MLForecast(\n",
        "    models=models,\n",
        "    freq='1mo',\n",
        "    lags=[1, 12], # create lags for previous month and same month last year\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "e4PQuewLyYdr",
        "outputId": "cc84a009-d94a-4e83-fa4f-6eb4d0442820"
      },
      "outputs": [],
      "source": [
        "# check what the preprocessed data looks like\n",
        "fcst.preprocess(Y_df.select(\"unique_id\", \"ds\", \"y\"), dropna=False).filter(pl.col(\"unique_id\").eq(\"Japan-big-elegant-3\")).sort(\"ds\").head(14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "d2uaUptbzexO",
        "outputId": "47e6570f-7d36-4d42-84dd-79014ab0e358"
      },
      "outputs": [],
      "source": [
        "# Another useful feature is the month so that the model is able to capture the seasonality\n",
        "fcst = MLForecast(\n",
        "    models=models,\n",
        "    freq='1mo',\n",
        "    lags=[1, 12], # create lags for previous month and same month last year\n",
        "    date_features=['month'], # create a feature for the month\n",
        ")\n",
        "fcst.preprocess(Y_df.select(\"unique_id\", \"ds\", \"y\"), dropna=False).filter(pl.col(\"unique_id\").eq(\"Japan-big-elegant-3\")).sort(\"ds\").head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "k25fDsPLz5rr",
        "outputId": "52f119fa-790f-4752-a601-2b96a0c572f8"
      },
      "outputs": [],
      "source": [
        "# rolling and expanding means help to capture the trend of a time series without the model having to reconstruct that from a lot of lags\n",
        "fcst = MLForecast(\n",
        "    models=models,\n",
        "    freq='1mo',\n",
        "    lags=[1, 12], # create lags for previous month and same month last year\n",
        "    lag_transforms={\n",
        "        1: [ExpandingMean(), RollingMean(window_size=4, min_samples=1)],\n",
        "        12: [ExpandingMean()]\n",
        "    },\n",
        "    date_features=['month'], # create a feature for the month\n",
        ")\n",
        "features = fcst.preprocess(Y_df.select(\"unique_id\", \"ds\", \"y\"), dropna=False).filter(pl.col(\"unique_id\").eq(\"Japan-big-elegant-3\")).sort(\"ds\")\n",
        "features.tail(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "9lHSW-SF0h6W",
        "outputId": "1ef53fc6-23d4-46ec-96cc-639614b7e8c7"
      },
      "outputs": [],
      "source": [
        "# visualizing the different features helps a lot\n",
        "px.line(features, x=\"ds\", y=[\"y\", \"lag1\", \"lag12\", \"expanding_mean_lag1\", \"rolling_mean_lag1_window_size4_min_samples1\", \"expanding_mean_lag12\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5npkYaFJ9QCA"
      },
      "source": [
        "## Making a prediction with a recursive one-step ahead forecaster\n",
        "\n",
        "To make a prediction we can simply call the fit method. This will create a one-step ahead forecast. A model that can predict the value for the next time step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRZYKrzV_z2t",
        "outputId": "5dc4bdb1-95a4-402e-e017-3a5f8b991d6b"
      },
      "outputs": [],
      "source": [
        "# now that we have prepared the features, we can fit a model\n",
        "fcst.fit(Y_df.select(\"unique_id\", \"ds\", \"y\"), dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFrSu8gl9hW2"
      },
      "source": [
        "Making the actual predictions can then be done using the predict method. This will recursively make the predictions (use the result of the first forecast to create the features for the second forecast)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "nevopZMgtEMz",
        "outputId": "cc8a7bb9-2bb7-4e16-ce7b-2b796d81eb6b"
      },
      "outputs": [],
      "source": [
        "# and make a prediction for one year ahead\n",
        "predictions = fcst.predict(12)\n",
        "predictions.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "qYlMVvuHvtPy",
        "outputId": "a52606c9-a7f4-4428-efca-9b922991b071"
      },
      "outputs": [],
      "source": [
        "# what is interesting: the model predicts all series, also those from the past that are no longer of interest!\n",
        "from utilsforecast.plotting import plot_series\n",
        "fig = plot_series(Y_df, predictions, max_ids=4, plot_random=False)\n",
        "fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "yRvz8CwSvthl",
        "outputId": "874e7315-07a7-4cc1-b407-83d47e2bc62e"
      },
      "outputs": [],
      "source": [
        "# beware of a cross validation in such a case!\n",
        "# You will validate against series from the training window!\n",
        "# THIS IS FUTURE LEAKAGE AT ITS FINEST!\n",
        "cv_result = fcst.cross_validation(\n",
        "    Y_df.select(\"unique_id\", \"ds\", \"y\"),\n",
        "    n_windows=4,  # number of models to train/splits to perform\n",
        "    h=12,  # length of the validation set in each window\n",
        ")\n",
        "cv_result.group_by(\"unique_id\").agg(pl.col(\"cutoff\").unique(), pl.col(\"cutoff\").n_unique().alias(\"n_cutoff\")).sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6IwNI0198iN"
      },
      "source": [
        "We can fill the time series before they start and after they finish to avoid this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "jOJ3Xyiw8S0D",
        "outputId": "eace2ad8-f5e8-45fe-c105-21a80b62d91a"
      },
      "outputs": [],
      "source": [
        "px.line(Y_df.filter(pl.col(\"unique_id\").eq(\"Italien-small-elegant-2\")), x=\"ds\", y=\"y\", title=\"Before filling with 0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "i_3iWCQk7unj",
        "outputId": "345f639a-bedc-4827-fac3-13b2ca4ae82b"
      },
      "outputs": [],
      "source": [
        "# adjust the time series to cover the complete range\n",
        "from utilsforecast.preprocessing import fill_gaps\n",
        "Y_df_filled = fill_gaps(Y_df, freq=\"1mo\", start=\"global\", end=\"global\").with_columns(pl.col(\"y\").fill_null(0))\n",
        "px.line(Y_df_filled.filter(pl.col(\"unique_id\").eq(\"Italien-small-elegant-2\")), x=\"ds\", y=\"y\", title=\"After filling with 0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Beware that we would have to adjust the features as well because fill_gaps is unaware of static features (country, segment, ...) and how to calculate the non-static features (e.g. months_till_eol, months_till_start)\n",
        "Y_df_filled.filter(pl.col(\"unique_id\").eq(\"Italien-small-elegant-2\")).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "lkWkILcB7u9_",
        "outputId": "42972adc-953b-4a12-d762-9d3726f619c3"
      },
      "outputs": [],
      "source": [
        "cv_result = fcst.cross_validation(\n",
        "    Y_df_filled.select(\"unique_id\", \"ds\", \"y\"),\n",
        "    n_windows=4,  # number of models to train/splits to perform\n",
        "    h=12,  # length of the validation set in each window\n",
        ")\n",
        "cv_result.group_by(\"unique_id\").agg(pl.col(\"cutoff\").unique(), pl.col(\"cutoff\").n_unique().alias(\"n_cutoff\")).sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsoLlNWcAjVj"
      },
      "source": [
        "## Hands-on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Filling with zeros to avoid the future leakage works. However, this is also really problematic. What have we done to the distribution of the training and test data? Is it now easier or harder for the model to predict `y`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# room for your thoughts or analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Try to do some feature engineering to improve the model\n",
        "- Play around with different lags and expanding means/rolling means\n",
        "- What is the best value you can get?\n",
        "- If that is boring for you, you can also have a look at the take home assignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSHYwzEKDMhA"
      },
      "outputs": [],
      "source": [
        "# copy and modify the code from above that creates the forecasting object fcst = MLForecast(...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "rFmYn2QVAiiG",
        "outputId": "2a9c940d-cdee-4e12-a9f5-3b6146fccc5f"
      },
      "outputs": [],
      "source": [
        "from utilsforecast.losses import rmse, mae, mape, bias\n",
        "\n",
        "cv_result = fcst.cross_validation(\n",
        "    Y_df.select(\"unique_id\", \"ds\", \"y\"),\n",
        "    n_windows=4,  # number of models to train/splits to perform\n",
        "    h=12,  # length of the validation set in each window\n",
        ")\n",
        "rmse(cv_result, models=['LGBMRegressor'], id_col='cutoff').select(pl.col(\"LGBMRegressor\").mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDJdCdGH_QzN"
      },
      "source": [
        "## Take home assignment\n",
        "\n",
        "\n",
        "You can explore various topics we could not cover today!\n",
        "\n",
        "- Add the static features for segment and type.\n",
        "- Add features that covers the lifecycle of the products (months since market introduction, months until end of lifecycle). See https://nixtlaverse.nixtla.io/mlforecast/docs/how-to-guides/exogenous_features.html\n",
        "- Add features that calculate the trend of the segment and the type (difficult with Nixtla!)\n",
        "- How could you give the model a hint regarding the level of a new time series (cold-start problem)?\n",
        "- Add features that cover predecessors of the product to be forecasted (which also helps for the cold-start problem)\n",
        "- The recursive approach comes with quite some downsides. Train one model per horizon to get better forecasts https://nixtlaverse.nixtla.io/mlforecast/docs/how-to-guides/one_model_per_horizon.html and check https://medium.com/data-science/the-perils-of-recursive-forecasting-82ebd218d147\n",
        "- Implement a proper rolling cross-validation\n",
        "    - prepend the individual time series based on the maximum forecast horizon (e.g. for 12 months you would prepend the time series with 12 time steps)\n",
        "    - implement the cross-validation to only forecast time series that are included in the validation window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
